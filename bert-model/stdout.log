2019-04-25 23:57:02,288 - INFO - allennlp.common.params - evaluate_on_test = False
2019-04-25 23:57:02,288 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'sst_tokens'} and extras set()
2019-04-25 23:57:02,288 - INFO - allennlp.common.params - dataset_reader.type = sst_tokens
2019-04-25 23:57:02,288 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.stanford_sentiment_tree_bank.StanfordSentimentTreeBankDatasetReader'> from params {'token_indexers': {'bert': {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
2019-04-25 23:57:02,289 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras set()
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained
2019-04-25 23:57:02,289 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': False, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': True} and extras set()
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2019-04-25 23:57:02,289 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2019-04-25 23:57:02,289 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Your BERT model appears to be uncased, but your indexer is not lowercasing tokens.
2019-04-25 23:57:03,020 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/andreas/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
2019-04-25 23:57:03,066 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.type = characters
2019-04-25 23:57:03,066 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.namespace = token_characters
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.start_tokens = None
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.end_tokens = None
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.token_indexers.token_characters.min_padding_length = 3
2019-04-25 23:57:03,066 - INFO - allennlp.common.params - dataset_reader.use_subtrees = False
2019-04-25 23:57:03,067 - INFO - allennlp.common.params - dataset_reader.granularity = 5-class
2019-04-25 23:57:03,067 - INFO - allennlp.common.params - dataset_reader.lazy = False
2019-04-25 23:57:03,067 - INFO - allennlp.common.params - validation_dataset_reader = None
2019-04-25 23:57:03,067 - INFO - allennlp.common.params - train_data_path = data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 23:57:03,067 - INFO - allennlp.training.util - Reading training data from data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 23:57:03,067 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/stanfordSentimentTreebank/trees/train.txt
2019-04-25 23:57:04,280 - INFO - allennlp.common.params - validation_data_path = data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 23:57:04,281 - INFO - allennlp.training.util - Reading validation data from data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 23:57:04,281 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank - Reading instances from lines in file at: data/stanfordSentimentTreebank/trees/dev.txt
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - test_data_path = None
2019-04-25 23:57:04,407 - INFO - allennlp.training.trainer - From dataset instances, train, validation will be considered for vocabulary creation.
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.type = None
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.extend = False
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.directory_path = None
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.min_count = None
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False
2019-04-25 23:57:04,407 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None
2019-04-25 23:57:04,407 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2019-04-25 23:57:05,107 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'encoder': {'hidden_size': 128, 'input_size': 896, 'type': 'lstm'}, 'type': 'lstm_classifier', 'word_embeddings': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
2019-04-25 23:57:05,107 - INFO - allennlp.common.params - model.type = lstm_classifier
2019-04-25 23:57:05,107 - INFO - allennlp.common.from_params - instantiating class <class 'bert.LstmClassifier'> from params {'encoder': {'hidden_size': 128, 'input_size': 896, 'type': 'lstm'}, 'word_embeddings': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
2019-04-25 23:57:05,107 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets'], 'token_characters': ['token_characters']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}, 'token_characters': {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
2019-04-25 23:57:05,107 - INFO - allennlp.common.params - model.word_embeddings.type = basic
2019-04-25 23:57:05,107 - INFO - allennlp.common.params - model.word_embeddings.allow_unmatched_keys = True
2019-04-25 23:57:05,108 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'} and extras {'vocab'}
2019-04-25 23:57:05,108 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.bert.type = bert-pretrained
2019-04-25 23:57:05,108 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased'} and extras {'vocab'}
2019-04-25 23:57:05,108 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.bert.pretrained_model = bert-base-uncased
2019-04-25 23:57:05,108 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.bert.requires_grad = False
2019-04-25 23:57:05,108 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.bert.top_layer_only = False
2019-04-25 23:57:05,817 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/andreas/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
2019-04-25 23:57:05,819 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /home/andreas/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8e7yvnf5
2019-04-25 23:57:09,078 - INFO - pytorch_pretrained_bert.modeling - Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

2019-04-25 23:57:10,697 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 16}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.type = character_encoding
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.num_embeddings = None
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.vocab_namespace = token_characters
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.embedding_dim = 16
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.pretrained_file = None
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.projection_dim = None
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.trainable = True
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.padding_index = None
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.max_norm = None
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.norm_type = 2.0
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.scale_grad_by_freq = False
2019-04-25 23:57:10,698 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.embedding.sparse = False
2019-04-25 23:57:10,698 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128, 'type': 'cnn'} and extras set()
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.type = cnn
2019-04-25 23:57:10,699 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 16, 'ngram_filter_sizes': [3], 'num_filters': 128} and extras set()
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.embedding_dim = 16
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.num_filters = 128
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.conv_layer_activation = relu
2019-04-25 23:57:10,699 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.encoder.output_dim = None
2019-04-25 23:57:10,701 - INFO - allennlp.common.params - model.word_embeddings.token_embedders.token_characters.dropout = 0.0
2019-04-25 23:57:10,701 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'hidden_size': 128, 'input_size': 896, 'type': 'lstm'} and extras {'vocab'}
2019-04-25 23:57:10,701 - INFO - allennlp.common.params - model.encoder.type = lstm
2019-04-25 23:57:10,701 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 23:57:10,702 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 23:57:10,702 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 23:57:10,702 - INFO - allennlp.common.params - model.encoder.hidden_size = 128
2019-04-25 23:57:10,702 - INFO - allennlp.common.params - model.encoder.input_size = 896
2019-04-25 23:57:10,702 - INFO - allennlp.common.params - model.encoder.batch_first = True
2019-04-25 23:57:10,705 - INFO - allennlp.common.params - model.positive_label = 4
2019-04-25 23:57:10,706 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.type = bucket
2019-04-25 23:57:10,707 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.padding_noise = 0.1
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.biggest_batch_first = False
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.batch_size = 32
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.instances_per_epoch = None
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.cache_instances = False
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.track_epoch = False
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - validation_iterator = None
2019-04-25 23:57:10,707 - INFO - allennlp.common.params - trainer.no_grad = ()
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2019-04-25 23:57:10,709 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2019-04-25 23:57:10,710 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2019-04-25 23:57:10,711 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2019-04-25 23:57:10,712 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2019-04-25 23:57:10,713 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2019-04-25 23:57:10,714 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2019-04-25 23:57:10,715 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2019-04-25 23:57:10,716 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2019-04-25 23:57:10,717 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2019-04-25 23:57:10,718 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.pooler.dense.weight
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert.bert_model.pooler.dense.bias
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.gamma
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.0
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.1
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.2
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.3
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.4
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.5
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.6
2019-04-25 23:57:10,719 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.7
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.8
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.9
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.10
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_bert._scalar_mix.scalar_parameters.11
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_token_characters._embedding._module.weight
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_token_characters._encoder._module.conv_layer_0.weight
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - word_embeddings.token_embedder_token_characters._encoder._module.conv_layer_0.bias
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - encoder._module.weight_ih_l0
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - encoder._module.weight_hh_l0
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - encoder._module.bias_ih_l0
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - encoder._module.bias_hh_l0
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - linear.weight
2019-04-25 23:57:10,720 - INFO - allennlp.training.trainer - linear.bias
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.patience = 5
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.validation_metric = -loss
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.shuffle = True
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.num_epochs = 50
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.cuda_device = -1
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.grad_norm = None
2019-04-25 23:57:10,720 - INFO - allennlp.common.params - trainer.grad_clipping = None
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - trainer.optimizer = adam
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - parameter_groups = None
2019-04-25 23:57:10,721 - INFO - allennlp.training.optimizers - Number of trainable parameters: 533794
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - infer_type_and_cast = True
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
2019-04-25 23:57:10,721 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: 
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.model_save_interval = None
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.summary_interval = 100
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.histogram_interval = None
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False
2019-04-25 23:57:10,722 - INFO - allennlp.common.params - trainer.log_batch_size_period = None
2019-04-25 23:57:10,760 - INFO - root - Failed to import cuda module: No module named 'caffe2.python.caffe2_pybind11_state_gpu'
2019-04-25 23:57:10,761 - INFO - root - Failed to import AMD hip module: No module named 'caffe2.python.caffe2_pybind11_state_hip'
2019-04-25 23:57:10,761 - WARNING - root - This caffe2 python run does not have GPU support. Will run in CPU only mode.
2019-04-25 23:57:10,767 - INFO - allennlp.training.trainer - Beginning training.
2019-04-25 23:57:10,767 - INFO - allennlp.training.trainer - Epoch 0/49
2019-04-25 23:57:10,767 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1154.34
2019-04-25 23:57:10,790 - INFO - allennlp.training.trainer - Training
2019-04-26 00:03:32,891 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:04:44,712 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:04:44,712 - INFO - allennlp.training.tensorboard_writer - recall        |     0.073  |     0.022
2019-04-26 00:04:44,714 - INFO - allennlp.training.tensorboard_writer - precision     |     0.437  |     0.750
2019-04-26 00:04:44,715 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.402  |     0.451
2019-04-26 00:04:44,715 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1154.340  |       N/A
2019-04-26 00:04:44,716 - INFO - allennlp.training.tensorboard_writer - loss          |     1.363  |     1.253
2019-04-26 00:04:44,716 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.125  |     0.042
2019-04-26 00:04:45,125 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'bert-model/best.th'.
2019-04-26 00:04:45,639 - INFO - allennlp.training.trainer - Epoch duration: 00:07:34
2019-04-26 00:04:45,639 - INFO - allennlp.training.trainer - Estimated training time remaining: 6:11:28
2019-04-26 00:04:45,640 - INFO - allennlp.training.trainer - Epoch 1/49
2019-04-26 00:04:45,640 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1542.848
2019-04-26 00:04:45,691 - INFO - allennlp.training.trainer - Training
2019-04-26 00:10:27,233 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:11:01,036 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:11:01,036 - INFO - allennlp.training.tensorboard_writer - recall        |     0.263  |     0.288
2019-04-26 00:11:01,037 - INFO - allennlp.training.tensorboard_writer - precision     |     0.543  |     0.541
2019-04-26 00:11:01,037 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.485  |     0.499
2019-04-26 00:11:01,038 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1542.848  |       N/A
2019-04-26 00:11:01,038 - INFO - allennlp.training.tensorboard_writer - loss          |     1.182  |     1.180
2019-04-26 00:11:01,039 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.354  |     0.376
2019-04-26 00:11:01,267 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'bert-model/best.th'.
2019-04-26 00:11:03,445 - INFO - allennlp.training.trainer - Epoch duration: 00:06:17
2019-04-26 00:11:03,445 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:33:04
2019-04-26 00:11:03,445 - INFO - allennlp.training.trainer - Epoch 2/49
2019-04-26 00:11:03,445 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1542.848
2019-04-26 00:11:03,477 - INFO - allennlp.training.trainer - Training
2019-04-26 00:16:15,742 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:16:51,812 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:16:51,812 - INFO - allennlp.training.tensorboard_writer - recall        |     0.370  |     0.388
2019-04-26 00:16:51,813 - INFO - allennlp.training.tensorboard_writer - precision     |     0.604  |     0.478
2019-04-26 00:16:51,813 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.548  |     0.477
2019-04-26 00:16:51,814 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1542.848  |       N/A
2019-04-26 00:16:51,814 - INFO - allennlp.training.tensorboard_writer - loss          |     1.060  |     1.205
2019-04-26 00:16:51,814 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.459  |     0.429
2019-04-26 00:16:52,072 - INFO - allennlp.training.trainer - Epoch duration: 00:05:48
2019-04-26 00:16:52,072 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:08:27
2019-04-26 00:16:52,072 - INFO - allennlp.training.trainer - Epoch 3/49
2019-04-26 00:16:52,072 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1613.232
2019-04-26 00:16:52,109 - INFO - allennlp.training.trainer - Training
2019-04-26 00:25:11,846 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:25:48,710 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:25:48,711 - INFO - allennlp.training.tensorboard_writer - recall        |     0.507  |     0.338
2019-04-26 00:25:48,711 - INFO - allennlp.training.tensorboard_writer - precision     |     0.675  |     0.480
2019-04-26 00:25:48,712 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.626  |     0.477
2019-04-26 00:25:48,712 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1613.232  |       N/A
2019-04-26 00:25:48,712 - INFO - allennlp.training.tensorboard_writer - loss          |     0.909  |     1.235
2019-04-26 00:25:48,713 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.579  |     0.397
2019-04-26 00:25:48,951 - INFO - allennlp.training.trainer - Epoch duration: 00:08:56
2019-04-26 00:25:48,951 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:29:19
2019-04-26 00:25:48,951 - INFO - allennlp.training.trainer - Epoch 4/49
2019-04-26 00:25:48,951 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1616.632
2019-04-26 00:25:48,988 - INFO - allennlp.training.trainer - Training
2019-04-26 00:31:41,936 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:32:16,871 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:32:16,871 - INFO - allennlp.training.tensorboard_writer - recall        |     0.631  |     0.410
2019-04-26 00:32:16,872 - INFO - allennlp.training.tensorboard_writer - precision     |     0.735  |     0.475
2019-04-26 00:32:16,872 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.718  |     0.470
2019-04-26 00:32:16,873 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1616.632  |       N/A
2019-04-26 00:32:16,873 - INFO - allennlp.training.tensorboard_writer - loss          |     0.712  |     1.364
2019-04-26 00:32:16,873 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.679  |     0.440
2019-04-26 00:32:17,120 - INFO - allennlp.training.trainer - Epoch duration: 00:06:28
2019-04-26 00:32:17,120 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:15:57
2019-04-26 00:32:17,120 - INFO - allennlp.training.trainer - Epoch 5/49
2019-04-26 00:32:17,120 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1666.812
2019-04-26 00:32:17,154 - INFO - allennlp.training.trainer - Training
2019-04-26 00:38:04,989 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:38:42,820 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2019-04-26 00:38:42,820 - INFO - allennlp.training.tensorboard_writer - recall        |     0.774  |     0.460
2019-04-26 00:38:42,821 - INFO - allennlp.training.tensorboard_writer - precision     |     0.836  |     0.457
2019-04-26 00:38:42,822 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.813  |     0.431
2019-04-26 00:38:42,822 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1666.812  |       N/A
2019-04-26 00:38:42,823 - INFO - allennlp.training.tensorboard_writer - loss          |     0.521  |     1.514
2019-04-26 00:38:42,825 - INFO - allennlp.training.tensorboard_writer - f1_measure    |     0.804  |     0.459
2019-04-26 00:38:43,148 - INFO - allennlp.training.trainer - Epoch duration: 00:06:26
2019-04-26 00:38:43,148 - INFO - allennlp.training.trainer - Estimated training time remaining: 5:04:37
2019-04-26 00:38:43,148 - INFO - allennlp.training.trainer - Epoch 6/49
2019-04-26 00:38:43,148 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1666.812
2019-04-26 00:38:43,204 - INFO - allennlp.training.trainer - Training
2019-04-26 00:44:48,177 - INFO - allennlp.training.trainer - Validating
2019-04-26 00:45:24,801 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2019-04-26 00:45:24,801 - INFO - allennlp.training.checkpointer - loading best weights
